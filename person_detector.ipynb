{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person Detector #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to find the person in the image so that the person can be cropped out and be used in the project. This will create a more accurate result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from yolov3.utils import Load_Yolo_model, image_preprocess, postprocess_boxes, nms\n",
    "from yolov3.configs import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import images ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"./reference_pose/c_migi_gedan_barai.png\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop image function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image, bboxes):\n",
    "    for bbox in bboxes:\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "\n",
    "        # crop image\n",
    "        cropped_image = image[y1-30:y2+30, x1-30:x2+30]\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_image(Yolo, image_path, output_path, input_size=416, show=False, score_threshold=0.3, iou_threshold=0.45):\n",
    "    original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image_data = image_preprocess(np.copy(original_image), [\n",
    "                                  input_size, input_size])\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "    if YOLO_FRAMEWORK == \"tf\":\n",
    "        pred_bbox = Yolo.predict(image_data)\n",
    "    elif YOLO_FRAMEWORK == \"trt\":\n",
    "        batched_input = tf.constant(image_data)\n",
    "        result = Yolo(batched_input)\n",
    "        pred_bbox = []\n",
    "        for key, value in result.items():\n",
    "            value = value.numpy()\n",
    "            pred_bbox.append(value)\n",
    "\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "    bboxes = postprocess_boxes(\n",
    "        pred_bbox, original_image, input_size, score_threshold)\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "\n",
    "    image = crop(original_image, bboxes)\n",
    "    # CreateXMLfile(\"XML_Detections\", str(int(time.time())), original_image, bboxes, read_class_names(CLASSES))\n",
    "\n",
    "    if output_path != '':\n",
    "        cv2.imwrite(output_path, image)\n",
    "    if show:\n",
    "        # Show the image\n",
    "        cv2.imshow(\"Predicted image\", image)\n",
    "        # Load and hold the image\n",
    "        cv2.waitKey(0)\n",
    "        # To close the window after the required kill value was provided\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load yolo model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = Load_Yolo_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect and crop images ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 493ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 56,  75,  91],\n",
       "        [ 56,  75,  91],\n",
       "        [ 56,  75,  91],\n",
       "        ...,\n",
       "        [ 59,  77,  98],\n",
       "        [ 59,  77,  98],\n",
       "        [ 59,  77,  98]],\n",
       "\n",
       "       [[ 56,  75,  91],\n",
       "        [ 56,  75,  91],\n",
       "        [ 56,  75,  91],\n",
       "        ...,\n",
       "        [ 59,  77,  98],\n",
       "        [ 59,  77,  98],\n",
       "        [ 59,  77,  98]],\n",
       "\n",
       "       [[ 56,  75,  91],\n",
       "        [ 56,  75,  91],\n",
       "        [ 56,  75,  91],\n",
       "        ...,\n",
       "        [ 58,  76,  97],\n",
       "        [ 58,  76,  97],\n",
       "        [ 58,  76,  97]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[137, 188, 226],\n",
       "        [137, 188, 226],\n",
       "        [137, 188, 226],\n",
       "        ...,\n",
       "        [131, 186, 222],\n",
       "        [132, 187, 223],\n",
       "        [132, 187, 223]],\n",
       "\n",
       "       [[137, 187, 226],\n",
       "        [137, 187, 226],\n",
       "        [136, 186, 225],\n",
       "        ...,\n",
       "        [131, 186, 222],\n",
       "        [132, 187, 223],\n",
       "        [132, 187, 223]],\n",
       "\n",
       "       [[136, 186, 225],\n",
       "        [136, 186, 225],\n",
       "        [136, 186, 225],\n",
       "        ...,\n",
       "        [132, 187, 223],\n",
       "        [132, 187, 223],\n",
       "        [133, 188, 224]]], dtype=uint8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_and_crop_image(yolo, image, '', show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karate-trainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e7ead78e6b3ff796c6a295dea41d22dbcc7ad8777260a88e925872abe439df3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

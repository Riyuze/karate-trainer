{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person Detector #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to find the person in the image so that the person can be cropped out and be used in the project. This will create a more accurate result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from yolov3.utils import Load_Yolo_model, image_preprocess, postprocess_boxes, nms, draw_bbox\n",
    "from yolov3.configs import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import images ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"./reference_pose/p_hidari_chudan_oi_zuki.png\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop image function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image, bboxes):\n",
    "    for bbox in bboxes:\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "\n",
    "        # crop image\n",
    "        cropped_image = image[x1:y1, x2:y2]\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_image(Yolo, image_path, output_path, input_size=416, show=False, score_threshold=0.3, iou_threshold=0.45):\n",
    "    original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image_data = image_preprocess(np.copy(original_image), [\n",
    "                                  input_size, input_size])\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "    if YOLO_FRAMEWORK == \"tf\":\n",
    "        pred_bbox = Yolo.predict(image_data)\n",
    "    elif YOLO_FRAMEWORK == \"trt\":\n",
    "        batched_input = tf.constant(image_data)\n",
    "        result = Yolo(batched_input)\n",
    "        pred_bbox = []\n",
    "        for key, value in result.items():\n",
    "            value = value.numpy()\n",
    "            pred_bbox.append(value)\n",
    "\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "    bboxes = postprocess_boxes(\n",
    "        pred_bbox, original_image, input_size, score_threshold)\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "\n",
    "    image = crop(original_image, bboxes)\n",
    "    # CreateXMLfile(\"XML_Detections\", str(int(time.time())), original_image, bboxes, read_class_names(CLASSES))\n",
    "\n",
    "    if output_path != '':\n",
    "        cv2.imwrite(output_path, image)\n",
    "    if show:\n",
    "        # Show the image\n",
    "        cv2.imshow(\"predicted image\", image)\n",
    "        # Load and hold the image\n",
    "        cv2.waitKey(0)\n",
    "        # To close the window after the required kill value was provided\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = Load_Yolo_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 704ms/step\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m detect_and_crop_image(yolo, image, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, show\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[40], line 27\u001b[0m, in \u001b[0;36mdetect_and_crop_image\u001b[1;34m(Yolo, image_path, output_path, input_size, show, score_threshold, iou_threshold)\u001b[0m\n\u001b[0;32m     23\u001b[0m bboxes \u001b[39m=\u001b[39m postprocess_boxes(\n\u001b[0;32m     24\u001b[0m     pred_bbox, original_image, input_size, score_threshold)\n\u001b[0;32m     25\u001b[0m bboxes \u001b[39m=\u001b[39m nms(bboxes, iou_threshold, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnms\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m image \u001b[39m=\u001b[39m crop(original_image, bboxes)\n\u001b[0;32m     28\u001b[0m \u001b[39m# CreateXMLfile(\"XML_Detections\", str(int(time.time())), original_image, bboxes, read_class_names(CLASSES))\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39mif\u001b[39;00m output_path \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn[39], line 9\u001b[0m, in \u001b[0;36mcrop\u001b[1;34m(image, bboxes)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[39m# crop image\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     cropped_image \u001b[39m=\u001b[39m image[x1:y1, x2:y2]\n\u001b[1;32m----> 9\u001b[0m     cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m\"\u001b[39;49m\u001b[39mcropped\u001b[39;49m\u001b[39m\"\u001b[39;49m, cropped_image)\n\u001b[0;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m cropped_image\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "detect_and_crop_image(yolo, image, '', show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karate-trainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e7ead78e6b3ff796c6a295dea41d22dbcc7ad8777260a88e925872abe439df3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
